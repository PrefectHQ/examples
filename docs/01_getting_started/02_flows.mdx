<a href="https://github.com/griggz/prefect-examples-test/blob/main/01_getting_started/02_flows.py" target="_blank" style="float: right; padding: 6px 12px; background-color: #24292e; color: #ffffff; border-radius: 4px; text-decoration: none; font-size: 0.875rem; font-weight: 500;">View on GitHub</a>


## Prefect Flows ‚Äì The Beating Heart of Your Pipeline

A *flow* in Prefect is a container for the logic of your workflow ‚Äî it orchestrates
**tasks**, parameters, schedules, and more.  Think of it as the main function that
glues everything together but with super-powers: retries, caching, mapping, and
an interactive UI in Prefect Cloud.

In this guided tutorial, you'll learn to:
* Define tasks with `@task`
* Organize those tasks inside a `@flow`
* Pass parameters to make your flow reusable
* Run and observe the flow locally (no Prefect server required)

> **Tip**: You can still follow along even if you've never touched Prefect before.
  All you need is Python ‚â•3.10 and `uv add prefect`.

For a deeper dive into flow fundamentals, see the official Prefect docs:
https://docs.prefect.io/v3/develop/write-flows#write-and-run-flows

### When should you use a flow?
* **Orchestrating multiple tasks** ‚Äì whenever you have more than one step, wrap
  them in a flow for observability and resilience.
* **Production pipelines** ‚Äì flows provide retries, logging, and a UI out of the
  box.
* **Ad-hoc scripts** ‚Äì yes, even one-off data cleanup scripts benefit from
  Prefect's visibility.

**Best practice**: Keep flows small and focused. Delegate heavy lifting to tasks and use parameters to keep flows reusable.

```python
from datetime import datetime
from random import randint
from time import sleep

from prefect import flow, task, get_run_logger

```

---------------------------------------------------------------------------
Component 1 ‚Äì Define reusable tasks
---------------------------------------------------------------------------
Tasks are the building blocks of a flow.  Each task executes a single piece of
logic and can be retried, cached, or run in parallel.

```python
@task(retries=2, retry_delay_seconds=5)
def fetch_data(size: int) -> list[int]:
    """Simulate pulling records from an API or database."""
    logger = get_run_logger()
    logger.info("Fetching %s rows of data‚Ä¶", size)
    # Simulate flaky network by randomly failing
    if randint(0, 4) == 0:
        raise RuntimeError("Random fetch failure ‚Äì triggering retry‚Ä¶")
    sleep(1)
    return list(range(size))


@task
def transform(data: list[int]) -> list[int]:
    """A trivial transformation ‚Äì square each number."""
    logger = get_run_logger()
    logger.info("Transforming %s rows‚Ä¶", len(data))
    return [x**2 for x in data]


@task
def load(data: list[int]) -> None:
    """Pretend to write the data somewhere (here we just log)."""
    logger = get_run_logger()
    logger.info("Loaded %s rows!", len(data))


```

---------------------------------------------------------------------------
Component 2 ‚Äì Compose a flow 
---------------------------------------------------------------------------
Flows orchestrate tasks. They can accept parameters, call tasks (or other
flows), and return results.

```python
@flow(log_prints=True)
def tutorial_flow(
    rows: int = 10,
    run_name: str = f"tutorial-run-{datetime.utcnow().strftime('%Y%m%dT%H%M%S')}",
):
    """End-to-end example that fetches, transforms, and loads data.

    Args:
        rows: Number of rows to fetch.
        run_name: A friendly name that will appear in the Prefect UI.
    """
    logger = get_run_logger()
    logger.info("üóÇÔ∏è  Starting flow '%s' to process %s rows", run_name, rows)

    raw = fetch_data(rows)
    cleaned = transform(raw)
    load(cleaned)

    logger.info("‚úÖ Flow completed!")
    return len(cleaned)


```

---------------------------------------------------------------------------
What happens when you run this file? 
---------------------------------------------------------------------------
1. Prefect registers the tasks (`fetch_data`, `transform`, `load`).
2. `tutorial_flow` is invoked within the `__main__` guard.
3. Logs appear in your terminal; retries happen automatically on failure.
4. Open the Prefect UI (prefect Orion) to see your run: `prefect orion start`.

**Next steps**:
* Experiment with different `rows` values.
* Change `retries` or `retry_delay_seconds` on the `fetch_data` task.
* Add a parameter to change the square exponent!

### Running the example locally
```bash
python 01_getting_started/02_flows.py
```
The script will fetch, transform, and "load" a configurable number of rows while printing logs to your terminal. Any transient failures in `fetch_data` trigger automatic retries.

## Code organization
1. **Imports & setup** ‚Äì standard libraries plus `prefect` helpers
2. **Component 1 ‚Äì reusable tasks** (`fetch_data`, `transform`, `load`)
3. **Component 2 ‚Äì flow orchestration** (`tutorial_flow`)
4. **Execution guard** ‚Äì runs the flow when the file is executed directly

### What just happened?
When you executed the script, Prefect performed the following steps:
1. Registered the three tasks along with their retry logic.
2. Started a **flow run** named after the current timestamp.
3. Ran `fetch_data`; if it failed, Prefect retried up to 2 times.
4. Piped the successful output into `transform`, then into `load`.
5. Logged every step so you have full observability in the UI and CLI.

**Key takeaway**: A flow bundles multiple tasks into a robust, observable unit of work that you can schedule, parameterize, and monitor‚Äîall with minimal boilerplate.

```python
if __name__ == "__main__":
    # Run the flow with a custom parameter value
    tutorial_flow(rows=25) 
```
